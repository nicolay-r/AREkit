{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPa3fQn2zVN2YK/rbdR1JY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolay-r/AREkit/blob/master/arenets_colab_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AREnets colab quick start tutorial\n",
        "\n",
        "## Setup Python 3.6.9 Environment\n",
        "In this section we setup `python-3.6` requireed by tensorflow version `1.14.0`"
      ],
      "metadata": {
        "id": "GFtrYfHLn9Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install python\n",
        "!sudo apt-get install python3.6\n",
        "# change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1\n",
        "# select python version\n",
        "!sudo update-alternatives --config python3\n",
        "# check python version\n",
        "!python --version\n",
        "# install pip for new python \n",
        "!sudo apt-get install python3.6-distutils\n",
        "!wget https://bootstrap.pypa.io/pip/3.6/get-pip.py\n",
        "!sudo python get-pip.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1ktkLcs4NUp",
        "outputId": "68c48171-d383-40ee-bfe7-39c110bb66bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.6 is already the newest version (3.6.15-1+focal3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "  0            /usr/bin/python3.6   1         auto mode\n",
            "* 1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.8   1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 1\n",
            "Python 3.6.15\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.6-distutils is already the newest version (3.6.15-1+focal3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "--2023-01-26 11:56:36--  https://bootstrap.pypa.io/pip/3.6/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2159061 (2.1M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-01-26 11:56:36 (285 MB/s) - ‘get-pip.py’ saved [2159061/2159061]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip<22.0\n",
            "  Using cached pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.3.1\n",
            "    Uninstalling pip-21.3.1:\n",
            "      Successfully uninstalled pip-21.3.1\n",
            "Successfully installed pip-21.3.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCNEJNTr1JzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a155cfa-37b2-4225-c5c9-844beff5dfb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping arenets as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/nicolay-r/AREnets@0.23.0\n",
            "  Cloning https://github.com/nicolay-r/AREnets (to revision 0.23.0) to /tmp/pip-req-build-9bpl0dh9\n",
            "  Running command git clone --filter=blob:none -q https://github.com/nicolay-r/AREnets /tmp/pip-req-build-9bpl0dh9\n",
            "  Running command git checkout -b 0.23.0 --track origin/0.23.0\n",
            "  Switched to a new branch '0.23.0'\n",
            "  Branch '0.23.0' set up to track remote branch '0.23.0' from 'origin'.\n",
            "  Resolved https://github.com/nicolay-r/AREnets to commit d44c09922a65eb61c7b9d5e73cbffe9900fc6be2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm==4.41.1\n",
            "  Downloading tqdm-4.41.1-py2.py3-none-any.whl (56 kB)\n",
            "     |████████████████████████████████| 56 kB 2.6 MB/s            \n",
            "\u001b[?25hCollecting tensorflow-gpu==1.14.0\n",
            "  Downloading tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0 MB)\n",
            "     |████████████████████████████████| 377.0 MB 27 kB/s              \n",
            "\u001b[?25hCollecting astor>=0.6.0\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting wrapt>=1.11.1\n",
            "  Downloading wrapt-1.14.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (74 kB)\n",
            "     |████████████████████████████████| 74 kB 4.1 MB/s             \n",
            "\u001b[?25hCollecting absl-py>=0.7.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "     |████████████████████████████████| 126 kB 74.3 MB/s            \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gast>=0.2.0\n",
            "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "     |████████████████████████████████| 3.1 MB 67.2 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->arenets==0.23.0) (0.37.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "     |████████████████████████████████| 50 kB 8.9 MB/s             \n",
            "\u001b[?25hCollecting six>=1.10.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "     |████████████████████████████████| 488 kB 77.9 MB/s            \n",
            "\u001b[?25hCollecting grpcio>=1.8.6\n",
            "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "     |████████████████████████████████| 4.6 MB 72.6 MB/s            \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "     |████████████████████████████████| 42 kB 350 kB/s             \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "     |████████████████████████████████| 57 kB 6.1 MB/s             \n",
            "\u001b[?25hCollecting protobuf>=3.6.1\n",
            "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "     |████████████████████████████████| 1.1 MB 68.4 MB/s            \n",
            "\u001b[?25hCollecting numpy<2.0,>=1.14.5\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "     |████████████████████████████████| 14.8 MB 55.1 MB/s            \n",
            "\u001b[?25hCollecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "     |████████████████████████████████| 4.0 MB 59.3 MB/s            \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
            "     |████████████████████████████████| 289 kB 71.4 MB/s            \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "     |████████████████████████████████| 97 kB 9.4 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0->arenets==0.23.0) (59.6.0)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Collecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting typing-extensions>=3.6.4\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Building wheels for collected packages: arenets, termcolor\n",
            "  Building wheel for arenets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arenets: filename=arenets-0.23.0-py3-none-any.whl size=145604 sha256=5c86c0b1dbc064c9b35e68863986526b19cff8cb5485f0ccaf00474413ff1ab3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7q5r098z/wheels/46/24/99/a886a2685bb73bc2c5a06d436fd2d2a734bec376aed674bfb5\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=c026afc97f2e087144337596fb67c6639b7179ec146e3f97372f1053f5180319\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "Successfully built arenets termcolor\n",
            "Installing collected packages: zipp, typing-extensions, six, numpy, importlib-metadata, dataclasses, cached-property, werkzeug, protobuf, markdown, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, keras-preprocessing, keras-applications, google-pasta, gast, astor, tqdm, tensorflow-gpu, arenets\n",
            "Successfully installed absl-py-1.4.0 arenets-0.23.0 astor-0.8.1 cached-property-1.5.2 dataclasses-0.8 gast-0.5.3 google-pasta-0.2.0 grpcio-1.48.2 h5py-3.1.0 importlib-metadata-4.8.3 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.7 numpy-1.19.5 protobuf-3.19.6 six-1.16.0 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0 termcolor-1.1.0 tqdm-4.41.1 typing-extensions-4.1.1 werkzeug-2.0.3 wrapt-1.14.1 zipp-3.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!sudo pip uninstall arenets\n",
        "!sudo pip install git+https://github.com/nicolay-r/AREnets@0.23.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the code\n"
      ],
      "metadata": {
        "id": "ZzIIjAUslZbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content\"\n",
        "# clear prior local versions\n",
        "!rm ./*.py*\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/nn_config.py\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/predict.py\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/train.py"
      ],
      "metadata": {
        "id": "3Tf9DjBQziNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba93b849-352e-4270-cc23-76cdfb05a01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-01-26 11:57:58--  https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/nn_config.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 417 [text/plain]\n",
            "Saving to: ‘nn_config.py’\n",
            "\n",
            "nn_config.py        100%[===================>]     417  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 11:57:58 (27.5 MB/s) - ‘nn_config.py’ saved [417/417]\n",
            "\n",
            "--2023-01-26 11:57:58--  https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/predict.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 541 [text/plain]\n",
            "Saving to: ‘predict.py’\n",
            "\n",
            "predict.py          100%[===================>]     541  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 11:57:58 (29.5 MB/s) - ‘predict.py’ saved [541/541]\n",
            "\n",
            "--2023-01-26 11:57:59--  https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/train.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1143 (1.1K) [text/plain]\n",
            "Saving to: ‘train.py’\n",
            "\n",
            "train.py            100%[===================>]   1.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 11:57:59 (66.4 MB/s) - ‘train.py’ saved [1143/1143]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download input samples"
      ],
      "metadata": {
        "id": "5DFxruKEn9fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create folder for the data resources ..."
      ],
      "metadata": {
        "id": "f3GO9ztuBqUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/_data\""
      ],
      "metadata": {
        "id": "9vw2MgNHBdSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then place example data in it ..."
      ],
      "metadata": {
        "id": "_6m1gQyiBwKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/_data\"\n",
        "!rm *.jsonl*\n",
        "!rm *.tsv.gz*\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/_data/sample-train.tsv.gz\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/_data/sample-test.tsv.gz\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/_data/sample-train.jsonl\n",
        "!wget https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/_data/sample-test.jsonl"
      ],
      "metadata": {
        "id": "_KMYt-B7oAf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4404f8be-170c-488f-a61a-74c72770b3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/_data\n",
            "rm: cannot remove '*.jsonl*': No such file or directory\n",
            "rm: cannot remove '*.tsv.gz*': No such file or directory\n",
            "--2023-01-26 11:58:07--  https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/_data/sample-train.tsv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4727 (4.6K) [application/octet-stream]\n",
            "Saving to: ‘sample-train.tsv.gz’\n",
            "\n",
            "sample-train.tsv.gz 100%[===================>]   4.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 11:58:07 (54.6 MB/s) - ‘sample-train.tsv.gz’ saved [4727/4727]\n",
            "\n",
            "--2023-01-26 11:58:07--  https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/_data/sample-test.tsv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3071 (3.0K) [application/octet-stream]\n",
            "Saving to: ‘sample-test.tsv.gz’\n",
            "\n",
            "sample-test.tsv.gz  100%[===================>]   3.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 11:58:08 (55.0 MB/s) - ‘sample-test.tsv.gz’ saved [3071/3071]\n",
            "\n",
            "--2023-01-26 11:58:08--  https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/_data/sample-train.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36977 (36K) [text/plain]\n",
            "Saving to: ‘sample-train.jsonl’\n",
            "\n",
            "sample-train.jsonl  100%[===================>]  36.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-26 11:58:08 (90.2 MB/s) - ‘sample-train.jsonl’ saved [36977/36977]\n",
            "\n",
            "--2023-01-26 11:58:08--  https://raw.githubusercontent.com/nicolay-r/AREnets/0.23.0/tutorials/_data/sample-test.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25907 (25K) [text/plain]\n",
            "Saving to: ‘sample-test.jsonl’\n",
            "\n",
            "sample-test.jsonl   100%[===================>]  25.30K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-01-26 11:58:09 (15.5 MB/s) - ‘sample-test.jsonl’ saved [25907/25907]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare embedding\n",
        "You can choose your one from the [following resource](http://vectors.nlpl.eu/repository/20/6.zip) for mostly any language you want."
      ],
      "metadata": {
        "id": "ia0ufIsKmw4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://vectors.nlpl.eu/repository/20/6.zip -P \"/content/_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrg-nobCmzEx",
        "outputId": "49052126-590b-47a8-803f-e5be2d9d7791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 11:58:13--  http://vectors.nlpl.eu/repository/20/6.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 635351287 (606M) [application/zip]\n",
            "Saving to: ‘/content/_data/6.zip’\n",
            "\n",
            "6.zip               100%[===================>] 605.92M  12.7MB/s    in 50s     \n",
            "\n",
            "2023-01-26 11:59:05 (12.1 MB/s) - ‘/content/_data/6.zip’ saved [635351287/635351287]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/_data\"\n",
        "!unzip *.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9eszW-Kntlu",
        "outputId": "4cd75e3f-000b-46e7-f7fb-af22a041f85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/_data\n",
            "Archive:  6.zip\n",
            "  inflating: meta.json               \n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Please, use files in order to open up `train.py` and customize training script for your needs."
      ],
      "metadata": {
        "id": "8pL6nnKeleez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content\"\n",
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91CTslwoz-_W",
        "outputId": "b83f2ac2-3f45-4b8a-ea9e-0aae65528519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [False]: _data/vocab.txt\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [False]: _data/term_embedding.npz\n",
            "INFO:arenets.emb_converter:Converting original text-based embedding: _data/model.txt\n",
            "100%|█████████████████████████████████████████████████████████████████████| 302867/302867 [00:25<00:00, 11754.52words/s]\n",
            "INFO:arenets.arekit.contrib.utils.np_utils.vocab:Saving vocabulary [size=302866]: _data/vocab.txt\n",
            "INFO:arenets.arekit.contrib.utils.np_utils.embedding:Saving embedding [size=(302866, 300)]: _data/term_embedding.npz\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/configurations/base/base.py:190: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/configurations/base/base.py:190: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/sample-train.jsonl\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/vocab.txt\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/term_embedding.npz\n",
            "INFO:arenets.arekit.contrib.utils.np_utils.embedding:Embedding read [size=(302866, 300)]: _data/term_embedding.npz\n",
            "INFO:arenets.arekit.contrib.utils.np_utils.vocab:Loading vocabulary [size=302866]: _data/vocab.txt\n",
            "Filling bags collection [DataType.Train]: 100it [00:00, 4594.03it/s]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/architectures/base/base.py:343: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/architectures/base/base.py:343: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`NHWC` for data_format is deprecated, use `NWC` instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`NHWC` for data_format is deprecated, use `NWC` instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/architectures/cnn.py:59: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/architectures/cnn.py:59: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:04,  1.03s/mbs]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:54.568331: Epoch: 1: avg_loss: 54.388, avg_acc: 0.547\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  8.74mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:55.086701: Epoch: 2: avg_loss: 44.787, avg_acc: 0.633\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  8.99mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:55.544197: Epoch: 3: avg_loss: 38.608, avg_acc: 0.633\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.65mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:55.968446: Epoch: 4: avg_loss: 34.791, avg_acc: 0.648\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.11mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:56.418508: Epoch: 5: avg_loss: 32.82, avg_acc: 0.656\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.46mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:56.852605: Epoch: 6: avg_loss: 30.564, avg_acc: 0.672\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.46mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:57.286068: Epoch: 7: avg_loss: 33.254, avg_acc: 0.609\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  8.05mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:57.792840: Epoch: 8: avg_loss: 28.717, avg_acc: 0.625\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.01mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:58.247980: Epoch: 9: avg_loss: 28.097, avg_acc: 0.688\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.42mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:58.683856: Epoch: 10: avg_loss: 25.799, avg_acc: 0.672\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.43mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:59.119795: Epoch: 11: avg_loss: 22.115, avg_acc: 0.766\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.03mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:25:59.576813: Epoch: 12: avg_loss: 20.907, avg_acc: 0.797\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.44mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:26:00.011904: Epoch: 13: avg_loss: 19.777, avg_acc: 0.852\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.28mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:26:00.454120: Epoch: 14: avg_loss: 18.539, avg_acc: 0.93\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.71mbs/s]                                                                     \n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:26:00.875880: Epoch: 15: avg_loss: 16.769, avg_acc: 0.953\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.09mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:26:01.326521: Epoch: 16: avg_loss: 14.422, avg_acc: 0.961\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.27mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:26:01.770291: Epoch: 17: avg_loss: 12.103, avg_acc: 0.984\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  9.20mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:26:02.216329: Epoch: 18: avg_loss: 10.972, avg_acc: 0.992\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  8.45mbs/s]\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:26:02.701525: Epoch: 19: avg_loss: 10.238, avg_acc: 0.984\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~3 (Might be greater or equal, as the last bag is expanded)\n",
            "Training [DataType.Train]: 4mbs [00:00,  8.88mbs/s]\n",
            "INFO:arenets.core.callback.train_limiter:Stop Training Process: avg_fit_acc > 1.0\n",
            "INFO:arenets.core.callback.stat:2023-01-05 22:26:03.163264: Epoch: 20: avg_loss: 9.038, avg_acc: 1.0\n",
            "INFO:arenets.tf_helpers.nn_states:Update TensorFlow model state: _data/cnn/cnn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "\n",
        "Please, use files in order to open up `predict.py` and customize prediction script for your needs.\n"
      ],
      "metadata": {
        "id": "jwPyLMzPmZlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content\"\n",
        "!python predict.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtDHlgDv0CHe",
        "outputId": "a14c6a47-7899-4a60-e346-ea0f3d51f7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/vocab.txt\n",
            "INFO:arenets.arekit.contrib.utils.io_utils.utils:Check existence [True]: _data/term_embedding.npz\n",
            "INFO:arenets.arekit.contrib.utils.np_utils.embedding:Embedding read [size=(302866, 300)]: _data/term_embedding.npz\n",
            "INFO:arenets.arekit.contrib.utils.np_utils.vocab:Loading vocabulary [size=302866]: _data/vocab.txt\n",
            "Filling bags collection [DataType.Test]: 64it [00:00, 4152.26it/s]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/architectures/base/base.py:343: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`NHWC` for data_format is deprecated, use `NWC` instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/arenets/context/architectures/cnn.py:59: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "2023-01-05 22:26:18.913082: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2023-01-05 22:26:18.917969: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2023-01-05 22:26:19.678117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-05 22:26:19.678895: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2be8e00 executing computations on platform CUDA. Devices:\n",
            "2023-01-05 22:26:19.678928: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2023-01-05 22:26:19.680657: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2023-01-05 22:26:19.680896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2be9a40 executing computations on platform Host. Devices:\n",
            "2023-01-05 22:26:19.680930: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2023-01-05 22:26:19.681085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-01-05 22:26:19.681675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2023-01-05 22:26:19.681798: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-05 22:26:19.681877: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-05 22:26:19.681948: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-05 22:26:19.682023: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-05 22:26:19.682092: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-05 22:26:19.682165: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-05 22:26:19.682237: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-01-05 22:26:19.682255: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\n",
            "2023-01-05 22:26:19.682292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2023-01-05 22:26:19.682308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2023-01-05 22:26:19.682321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2023-01-05 22:26:19.699875: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "INFO:arenets.tf_helpers.nn_states:----------------------------------\n",
            "INFO:arenets.tf_helpers.nn_states:Loading Tensorflow model state: _data/cnn/\n",
            "INFO:arenets.tf_helpers.nn_states:----------------------------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from _data/cnn/cnn\n",
            "INFO:arenets.core.model:Minibatches passing per epoch count: ~2 (Might be greater or equal, as the last bag is expanded)\n",
            "Predict [DataType.Test]:   0%|                                                                   | 0/2 [00:00<?, ?mbs/s]2023-01-05 22:26:19.738084: W tensorflow/core/framework/allocator.cc:107] Allocation of 363439200 exceeds 10% of system memory.\n",
            "2023-01-05 22:26:19.819135: W tensorflow/core/framework/allocator.cc:107] Allocation of 363439200 exceeds 10% of system memory.\n",
            "2023-01-05 22:26:19.902876: W tensorflow/core/framework/allocator.cc:107] Allocation of 363439200 exceeds 10% of system memory.\n",
            "2023-01-05 22:26:20.137847: W tensorflow/core/framework/allocator.cc:107] Allocation of 363439200 exceeds 10% of system memory.\n",
            "2023-01-05 22:26:20.221378: W tensorflow/core/framework/allocator.cc:107] Allocation of 363439200 exceeds 10% of system memory.\n",
            "Predict [DataType.Test]: 3mbs [00:02,  1.02mbs/s]                                                                       \n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/hparams_C\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/hparams_W\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/hparams_b\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/hparams_W2\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/hparams_b2\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/idparams_x-DataType.Test\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/idparams_obj_ind-DataType.Test\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/idparams_subj_ind-DataType.Test\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/idparams_frame_inds-DataType.Test\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/idparams_frame_connotation_inds-DataType.Test\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/idparams_y_labels-DataType.Test\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/idparams_y_scaled_logits-DataType.Test\n",
            "INFO:arenets.np_utils.writer:Save: _data/cnn/hidden/idparams_y_etalon_labels-DataType.Test\n",
            "Writing output: 64rows [00:00, 157532.54rows/s]\n"
          ]
        }
      ]
    }
  ]
}